# sequence to sequence 

## 机器翻译
![](imgs/seq2seq.png)
### 疑问：a<0>是什么
### 疑问：decoder的结束标记在哪里？
在编码阶段法语单词按照时序每个单词依次输入(x1,x2...xT)，最后得到一个输出。
将输出输入解码生成y1,y1作为输入生成y2,.....,那么就这样一直循环下去吗?应该有个END OF的符号吧


## beam search 集束搜索
解码出的(y1,y2,y3....)是一系列的概率,需要找出条件概率最高的的组合,而不是贪心算法求出最大概率y1,根据y1生成y2,求最大概率y2....
![](imgs/beam-search.png)
### 具体算法
https://www.zhihu.com/question/54356960 
1. 第一步的时候，我们通过模型计算得到 $ y^{<1>} $的分布概率，选择前B个作为候选结果，设beam width =3 则如下图所示的"in", "jane", "september"
![](imgs/beam-search1.png)
2. 第二步的时候，我们已经选择出了in、jane、September作为第一个单词的三个最可能选择，beam search针对每个第一个单词考虑第二个单词的概率，例如针对单词“in”，我们将 $ y^{<1>} $ ='in'，然后将它喂给  解码输入2，输出结果$ y^{<2>} $  作为第二个单词的概率输出。我们的选择方法为：$ P(y^{<2>},"in"|x)=P(y^{<2>}|"in",x) P("in"|x) $,这样得到10000个候选，同样"jane","Septeber"也各自得到10000个候选总共30000个候选，选择概率最高的前3个，比如得到的结果是：
* in september
* jane is
* jane visits
3. 第三步的时候，同样我们将我们将$ y^{<1>} ='in'， y^{<2>} ='september'，$然后将它喂给$ x^{<3>} $，输出结果$ y^{<3>} $作为第三个单词的概率输出10000个选择，其他两组也一样，共30000个选择，选前3个，依次类推....,直到中止在句尾符号
**notice:** 如果beam width =1,则和贪心算法是一样的

### beam search 改进 length normalization 
在Seq2Seq中的beam search算法中采用beam search来搜索得到使得条件语言模型概率最大的序列，并介绍了搜索方法。
$$\arg\max_{y} P( y^{<1>},y^{<2>},y^{<3>},...y^{<T_y>}|x^{<1>},x^{<2>},...x^{<T_x>})  $$
其中 $ P(y^{<1>},y^{<2>},y^{<3>},...y^{<T_y>}|x)=P(y^{<1>}|x)P(y^{<2>}|y^{<1>},x)...P(y^{<T_y>}|y^{<1>},...,y^{<T_y-1>},x)$

因此我们的条件概率模型可以看作是求解下式：
$\arg\max_{y}\prod_{t=1}^{T_y} P(y^{<t>}|x,y^{<1>},...,y^{<t-1>}) $

**这里存在两个问题**
1. 数值溢出
上式是条件概率的乘积,因每一项都<1,很多项<1的数乘,可能造成数值下溢(numerical underflow),解决办法是加一个log变成各项相加
$$\arg\max_{y} \sum_{t=1}^{T_y}{\log P(y^{<t>}|x,y^{<1>},...,y^{<t-1>})}$$

2. 倾向于更短的翻译
   





## image captioning
**本质:** encoder编码阶段用CNN对图像就行编码

![](imgs/image-caption.png)






